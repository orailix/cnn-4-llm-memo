{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `cnn_4_llm_memo`\n",
    "\n",
    "# Copyright 2025-present Laboratoire d'Informatique de Polytechnique.\n",
    "# Apache Licence v2.0.\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(os.path.abspath('')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract patterns\n",
    "\n",
    "This notebook helps you localize the patterns and detect IDs you need, and extract a small proportion of attention patterns to analyze them locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localizing patterns\n",
    "\n",
    "First, you need to get the IDs of the experiments to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.patterns import PatternsConfig\n",
    "from src.detect import DetectConfig\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TARGET_TAX = \"merge_2_other_code_recollect_recite\"\n",
    "TARGET_TAX = \"merge_2_other_guess_recollect_recite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasyq52cr19yVj72U1ZkFQ\n"
     ]
    }
   ],
   "source": [
    "saved_id = None\n",
    "for child in Path(\"/Users/jeremie/Documents/01-Travail/01-Doctorat/regu-detect/output/patterns\").iterdir():\n",
    "    cfg = PatternsConfig.from_json(child / \"config.json\", reset_output_dir=True)\n",
    "    if cfg.tax_name == TARGET_TAX and cfg.size == \"12b\" and cfg.duplicates_threshold == 50:\n",
    "        saved_id = cfg.get_id()\n",
    "        print(saved_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T31DI1_xGRSqwVnaYg8RQA\n",
      "njf0kB4Oc0SuUStqC_T_gg\n",
      "j-55nwPUR6a3jK9uFnkeKg\n",
      "UjdbeBW91ldG1Qz2_USWTg\n",
      "4S9AQiT_hRv-u0DhEWUIBg\n",
      "3nhzGHe8LQTthAVVg0kDqQ\n",
      "_oz-DWAzlH4j8_LBpUzUsw\n",
      "A-nLMe3_FC9MGKF93jlRWA\n"
     ]
    }
   ],
   "source": [
    "saved_detect_id = None\n",
    "for child in Path(\"/Users/jeremie/Documents/01-Travail/01-Doctorat/regu-detect/output/detect\").iterdir():\n",
    "    cfg = DetectConfig.from_json(child / \"config.json\", reset_output_dir=True)\n",
    "    if cfg.patterns_config == saved_id:# and cfg.kernel_size == 6 and cfg.n_feat_cnn == 10 and cfg.head_pooling == \"max\":\n",
    "        saved_detect_id = cfg.get_id()\n",
    "        print(saved_detect_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting patterns\n",
    "\n",
    "Now, you can use these detect IDs and patterns IDs to extact the correct patterns. For example, notebook `05-interpretation_rasy` gives you `A-nL.pickle` which contains a list of sequence IDs to extract. Copy this file on the machine that stores the attention patterns, and run the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-nL\n",
    "pickle_path = \"/lustre/fsn1/projects/rech/yfw/upp42qa/h5management/A-nL.pickle\"\n",
    "h5_input_path = \"/lustre/fsn1/projects/rech/yfw/upp42qa/h5management/attention_patterns_rasy.h5py\"\n",
    "h5_output_path = \"/lustre/fsn1/projects/rech/yfw/upp42qa/h5management/attention_patterns_rasy_extract.h5py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pickle_path, \"rb\") as f:\n",
    "    sequence_list = pickle.load(f)\n",
    "\n",
    "print(len(sequence_list))\n",
    "type(sequence_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(h5_output_path, \"w\") as h5f_output:\n",
    "    with h5py.File(h5_input_path, \"r\") as h5f_input:\n",
    "        for sequence_id in sequence_list:\n",
    "            attention_pattern = h5f_input[str(sequence_id)][()]  # Load as np array\n",
    "            h5f_output.create_dataset(\n",
    "                str(sequence_id),\n",
    "                data=attention_pattern.astype(np.float16),\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
